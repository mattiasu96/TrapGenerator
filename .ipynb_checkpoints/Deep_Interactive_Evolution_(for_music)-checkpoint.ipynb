{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "as9jtKN899Cm"
   },
   "source": [
    "# Setup\n",
    "To demonstrate the generality of the algorithm to any latent variable model, we use a pretrained VAE model by Google Magenta, MusicVAE (found here: https://colab.research.google.com/notebook#fileId=/v2/external/notebooks/magenta/music_vae/music_vae.ipynb).\n",
    "\n",
    "Installs and imports all packages for the Magenta MusicVAE, alongside loading the basic 2-bar loop model (a bidirectional LSTM encoder based VAE). This notebook is meant to run natively on google cloud in Colaboratory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54-G9Pg4udN7"
   },
   "source": [
    "# Deep Interactive Evolution (for music)\n",
    "\n",
    "This is an unofficial implementation of the algorithm found in the paper \"Deep Interactive Evolution\" (https://arxiv.org/abs/1801.08230). In contrast to the original paper, this implementation uses a VAE (instead of a GAN) trained on 2-bar music (instead of images), to evolve a 2-bar sample the user prefers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6LJkEOC1yJH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"gsutil\" non è riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n",
      "\"apt-get\" non è riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n",
      "ERROR: apache-beam 2.16.0 has requirement oauth2client<4,>=2.0.1, but you'll have oauth2client 4.1.3 which is incompatible.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Accesso negato: 'C:\\\\Users\\\\Mattia\\\\AppData\\\\Local\\\\Temp\\\\pip-uninstall-4umyk8b9\\\\_yaml.cp37-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c715d6956758>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#print 'Importing libraries and defining some helper functions...'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmagenta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmusic\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmagenta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequences_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconcatenate_sequences\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "#print 'Copying checkpoints and example MIDI from GCS. This may take a few minutes...'\n",
    "!gsutil -q -m cp -R gs://download.magenta.tensorflow.org/models/music_vae/colab2/* /content/\n",
    "\n",
    "#print 'Installing dependencies...'\n",
    "!apt-get update -qq && apt-get install -qq libfluidsynth1 fluid-soundfont-gm build-essential libasound2-dev libjack-dev\n",
    "!pip install -qU pyfluidsynth pretty_midi\n",
    "\n",
    "if glob.glob('/content/magenta*.whl'):\n",
    "  !pip install -qU /content/magenta*.whl\n",
    "else:\n",
    "  !pip install -qU magenta\n",
    "\n",
    "# Hack to allow python to pick up the newly-installed fluidsynth lib.\n",
    "import ctypes.util\n",
    "def proxy_find_library(lib):\n",
    "  if lib == 'fluidsynth':\n",
    "    return 'libfluidsynth.so.1'\n",
    "  else:\n",
    "    return ctypes.util.find_library(lib)\n",
    "\n",
    "ctypes.util.find_library = proxy_find_library\n",
    "\n",
    "\n",
    "#print 'Importing libraries and defining some helper functions...'\n",
    "from google.colab import files\n",
    "import magenta.music as mm\n",
    "from magenta.music.sequences_lib import concatenate_sequences\n",
    "from magenta.models.music_vae import configs\n",
    "from magenta.models.music_vae.trained_model import TrainedModel\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def play(note_sequence):\n",
    "  mm.play_sequence(note_sequence, synth=mm.fluidsynth)\n",
    "  \n",
    "def slerp(p0, p1, t):\n",
    "  \"\"\"Spherical linear interpolation.\"\"\"\n",
    "  omega = np.arccos(np.dot(np.squeeze(p0/np.linalg.norm(p0)), np.squeeze(p1/np.linalg.norm(p1))))\n",
    "  so = np.sin(omega)\n",
    "  return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1\n",
    "\n",
    "def interpolate(model, start_seq, end_seq, num_steps, max_length=32,\n",
    "                assert_same_length=True, temperature=0.5, \n",
    "                individual_duration=4.0):\n",
    "  \"\"\"Interpolates between a start and end sequence.\"\"\"\n",
    "  _, mu, _ = model.encode([start_seq, end_seq], assert_same_length)\n",
    "  z = np.array([slerp(mu[0], mu[1], t) for t in np.linspace(0, 1, num_steps)])\n",
    "  note_sequences = model.decode(\n",
    "      length=max_length,\n",
    "      z=z,\n",
    "      temperature=temperature)\n",
    "\n",
    "#  print 'Start Seq Reconstruction'\n",
    "  play(note_sequences[0])\n",
    " # print 'End Seq Reconstruction'\n",
    "  play(note_sequences[-1])\n",
    "  #print 'Mean Sequence'\n",
    "  play(note_sequences[num_steps // 2])\n",
    " # print 'Start -> End Interpolation'\n",
    "  interp_seq = concatenate_sequences(note_sequences, [individual_duration] * len(note_sequences))\n",
    "  play(interp_seq)\n",
    "  mm.plot_sequence(interp_seq)\n",
    "  return interp_seq if num_steps > 3 else note_sequences[num_steps // 2]\n",
    "\n",
    "def download(note_sequence, filename):\n",
    "  mm.sequence_proto_to_midi_file(note_sequence, filename)\n",
    "  files.download(filename)\n",
    "\n",
    "#print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDuUxK64aVFD"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained model.\n",
    "mel_2bar_config = configs.CONFIG_MAP['cat-mel_2bar_big']\n",
    "mel_2bar = TrainedModel(mel_2bar_config, batch_size=4, checkpoint_dir_or_path='/content/checkpoints/mel_2bar_big.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HHV0887fh6Lf"
   },
   "outputs": [],
   "source": [
    "rangek = 10\n",
    "z_length = 512\n",
    "p = 0.5\n",
    "foreign = 2\n",
    "model = mel_2bar\n",
    "np.random.seed(0)\n",
    "\n",
    "z = np.random.randn(rangek, z_length)\n",
    "m, n = rangek, z_length\n",
    "\n",
    "print 'Evolution hyperparamter initialization and model definiton complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkwmYjyY-0yC"
   },
   "source": [
    "Some helper functions for the evolution process, as outlined in algorithm 2 of the paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05egthvZ-xyW"
   },
   "outputs": [],
   "source": [
    "def uniform(population):\n",
    "    pop_len = len(population)\n",
    "    a = population[np.random.randint(0, pop_len)]\n",
    "    b = population[np.random.randint(0, pop_len)]\n",
    "    mask = np.random.binomial(1, 0.5, z_length)\n",
    "    return mask*a + (1-mask)*b\n",
    "\n",
    "def mutate(individual, std):\n",
    "    mutate_cond = np.random.binomial(1, p, 1)\n",
    "    noise = std*np.random.randn(1, z_length)\n",
    "    return individual + mutate_cond * noise\n",
    "\n",
    "def evolve(z, indices, mutate_rate, shuffle=True):\n",
    "    selections = z[indices]\n",
    "    mutate_var = mutate_rate\n",
    "\n",
    "    diff = m - len(selections)\n",
    "    x = np.max([0, diff])\n",
    "    cross = np.array([mutate(uniform(selections), mutate_var) for i in range(x - foreign)]).squeeze(axis=1)\n",
    "\n",
    "    x = np.min((foreign, diff))\n",
    "    new = np.random.randn(x, z_length)\n",
    "\n",
    "    selections = np.array([mutate(selection, mutate_var) for selection in selections]).squeeze(axis=1)\n",
    "\n",
    "    z = np.vstack((selections, cross, new))\n",
    "    \n",
    "    # if not shuffle, the first n(selected) samples are mutated selected samples, \n",
    "    # the last n(foreign) samples are foreign samples, and all samples inbetween are crossovers\n",
    "    if shuffle:\n",
    "        np.random.shuffle(z) \n",
    "    return z\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dSD2u3fey_O1"
   },
   "source": [
    "#### Some of the samples I obtained:\n",
    "\n",
    "Start: https://github.com/irhumshafkat/deepIEmidi/blob/master/start.wav\n",
    "\n",
    "8 generations later: https://github.com/irhumshafkat/deepIEmidi/blob/master/8thgen.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4K6ywuAr7MD"
   },
   "source": [
    "To simulate the user selection process, keep running the next three cells in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tapRu9u0lKvb"
   },
   "outputs": [],
   "source": [
    "note_sequences = model.decode(\n",
    "      length=32,\n",
    "      z=z,\n",
    "      temperature=0.8)\n",
    "\n",
    "print 'Start Seq Reconstruction'\n",
    "for i in range(rangek):\n",
    "  print i \n",
    "  play(note_sequences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjl-DGzBtBXk"
   },
   "source": [
    "If at any stage you'd like to seperately store a sample in memory, run the next cell with the index of the desired sample. Else, do not run, skip. This does not influence the actual evolution process, it just assigns the latent code of a keeps a sample you liked most so far to the best_yet variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fwtf37qcAcnv"
   },
   "outputs": [],
   "source": [
    "best_yet = z[0] #insert the index of the best so far\n",
    "play(model.decode(\n",
    "      length=32,\n",
    "      z=best_yet.reshape(-1, 512),\n",
    "      temperature=0.8)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ikTMNH1si5c"
   },
   "source": [
    "Replace the elements in list selected with the actual indices of the samples you wish to keep and run the next cell, after which, restart the \"loop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06RA_TfBh5g3"
   },
   "outputs": [],
   "source": [
    "list_selected = [8, 0] # insert the indices of the samples you'd like to keep\n",
    "z = evolve(z, list_selected, mutate_rate=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JwN1T5BxdVmB"
   },
   "source": [
    "Now, rerun the cell that generated all the samples. With the z's evolved, it will now generate samples from the new batch of z latent vectors"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Deep Interactive Evolution (for music).ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
