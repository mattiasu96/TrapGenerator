{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(maxlen, num_chars, num_layers, num_units):\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "    for layer_idx in range(num_layers):\n",
    "        if layer_idx == 0:\n",
    "            #the size is maxlen x numchars. Maxlen is because of the length of a sentence (128 words) while num_chars=119\n",
    "            #which are the unique words in my vocabulary.\n",
    "            #NB: the input is one hot encoded over the vocabulary size (num_chars)\n",
    "            model.add(LSTM(num_units, return_sequences=True, input_shape=(maxlen, num_chars)))\n",
    "        else:\n",
    "            model.add(LSTM(num_units, return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(num_chars))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(is_character=False, maxlen=None, num_units=None, model_prefix=''):\n",
    "\n",
    "    character_mode = is_character\n",
    "\n",
    "    if character_mode:\n",
    "        if maxlen == None:\n",
    "            maxlen = 1024\n",
    "        if num_units == None:\n",
    "            num_units = 32\n",
    "        step = 2*17 # step to create training data for truncated-BPTT\n",
    "    else: # word mode\n",
    "        if maxlen == None:\n",
    "            maxlen = 256 # maxlength used in RNN input\n",
    "        if num_units == None: \n",
    "            num_units = 512 #number of unit per layer LSTM 512 \n",
    "        step = 16\n",
    "\n",
    "    if character_mode:\n",
    "        num_char_pred = maxlen*3/2\n",
    "    else: \n",
    "        num_char_pred = 17*30 #this should be the number of elements predicted in the output. How \"long\" is my output sequence\n",
    "\n",
    "    num_layers = 2\n",
    "    # \n",
    "    if character_mode:\n",
    "        prefix = 'char'\n",
    "    else:\n",
    "        prefix = 'word'\n",
    "\n",
    "    path = 'sample.txt' # Corpus file\n",
    "    text = open(path).read()\n",
    "    print('corpus length:', len(text))\n",
    "\n",
    "    if character_mode:\n",
    "        chars = set(text)\n",
    "    else:\n",
    "        chord_seq = text.split(' ')\n",
    "        chars = set(chord_seq) #contains the unique words in my dictionary. They are 119\n",
    "        text = chord_seq #contains the full text in an array format. Each entry of my array is a word of type 0xb0110101010 \n",
    "\n",
    "    char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "    indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "    num_chars = len(char_indices) #number of unique words in my training set\n",
    "    print('total chars:', num_chars)\n",
    "\n",
    "    # cut the text in semi-redundant sequences of maxlen characters\n",
    "\n",
    "    sentences = []\n",
    "    next_chars = []\n",
    "    #Here im creating the inputs and targets for my RNN. Each single input has length maxlen.\n",
    "    #Inputs are semi-redundant, in the sense that i take a length of maxlen=128 and the step is 8. So my first part of the input\n",
    "    #will be the same and the last 8 elements are \"new\". I'm just \"slitting\" of 8 notes ahead\n",
    "    for i in range(0, len(text) - maxlen, step): #iterates over the range with steps of 8.\n",
    "        sentences.append(text[i: i + maxlen])\n",
    "        next_chars.append(text[i + maxlen])\n",
    "    print('nb sequences:', len(sentences))\n",
    "    print('Vectorization...')\n",
    "    \n",
    "    #Here i'm creating the input dataset and target dataset for my network\n",
    "    #X is a tri-dimensional vector: 1 dimension -> Sentences, 2 dimension -> Single sentence, 3 dimension -> one hot encoded vector of the single word\n",
    "    #So basically i have a structure where i have N sentences of maxlen Words where each word is represented as a one hot vector of length num_chars\n",
    "    X = np.zeros((len(sentences), maxlen, num_chars), dtype=np.bool) #Input matrix\n",
    "    y = np.zeros((len(sentences), num_chars), dtype=np.bool) #Target Matrix\n",
    "    #Here i'm actually \"populating\" the matrixes, which were initialized with all zeros\n",
    "    print('Entering initialization cycle')\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, char_indices[char]] = 1 #NB: char in this case means a whole word like oxb01011101. With char_indices[char] i'm retrieving the index of my word inside my dictionary of (words,index)\n",
    "        #print('Finished input initialization')\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    print('Completed Vectorization')\n",
    "    # build the model: 2 stacked LSTM\n",
    "    model = get_model(maxlen, num_chars, num_layers, num_units) \n",
    "    \n",
    "    #Just some string declarations for folders management and names.\n",
    "    #NB: CHANGE THE / with \\ for windows! \n",
    "    result_directory = 'r_%s_%s_%d_%d_units' % (prefix, model_prefix, maxlen, num_units)\n",
    "    filepath_model = os.path.join(result_directory, 'best_model.hdf')\n",
    "\n",
    "    #filepath_model = '%sbest_model.hdf' % result_directory\n",
    "    description_model = '%s, %d layers, %d units, %d maxlen, %d steps' % (prefix, num_layers, num_units, maxlen, step)\n",
    "    \n",
    "    #Usual Model checkpoints and Early Stopping\n",
    "    checker = tf.keras.callbacks.ModelCheckpoint(filepath_model, monitor='loss', verbose=0, save_best_only=True, mode='auto')\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15, verbose=0, mode='auto')\n",
    "    \n",
    "    #create a result directory if it doesn't exist\n",
    "    if not os.path.exists(result_directory):\n",
    "        os.mkdir(result_directory)\n",
    "\n",
    "    # write a description file.\n",
    "    #creates an empty file with the drscription of my model as title\n",
    "    with open(result_directory+description_model, 'w') as f_description:\n",
    "        pass\n",
    "\n",
    "    # train the model, output generated text after each iteration\n",
    "    batch_size = 128 #Size of a training batch. So basically i'll update my loss function every 128 input sentences (usual batch gradient descent)\n",
    "    loss_history = []\n",
    "    pt_x = [1]\n",
    "    #An epoch is a complete iteration over the whole input training set. So 10 epochs means that i iterates 10 times over my input dataset\n",
    "    nb_epochs = [np.sum(pt_x[:i+1]) for i in range(len(pt_x))] #array containing many epochs length. The model will be fitted many times, one for each nb_epochs.\n",
    "\n",
    "    # not random seed, but the same seed for all.\n",
    "    #A random seed (or seed state, or just seed) is a number (or vector) used to initialize a pseudorandom number generator.\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "\n",
    "    for iteration, nb_epoch in zip(pt_x,nb_epochs):\n",
    "        if os.path.exists('stop_asap.keunwoo'):\n",
    "            os.remove('stop_asap.keunwoo')\n",
    "            break\n",
    "\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        \n",
    "        #fitting model over nb_epochs\n",
    "        #result = model.fit(X, y, batch_size=batch_size, nb_epoch=nb_epoch, callbacks=[checker, early_stop]) \n",
    "        #loss_history = loss_history + result.history['loss']\n",
    "\n",
    "        print ('Saving model after %d epochs...' % nb_epoch)\n",
    "        #Saving model weights. Saving a model trained over nb_epochs\n",
    "        #model.save_weights('%smodel_after_%d.hdf'%(result_directory, nb_epoch), overwrite=True) \n",
    "        model.load_weights(\"model_weights_16step.h5\")\n",
    "        w2 = model.get_weights()\n",
    "        print(w2)\n",
    "\n",
    "        \n",
    "        for diversity in [0.9, 1.0, 1.2]:\n",
    "            #creates a .txt file where i will save my predictions\n",
    "            with open(('%sresult_%s_iter_%02d_diversity_%4.2f.txt' % (result_directory, prefix, iteration, diversity)), 'w') as f_write:\n",
    "\n",
    "                print()\n",
    "                print('----- diversity:', diversity)\n",
    "                f_write.write('diversity:%4.2f\\n' % diversity)\n",
    "                if character_mode:\n",
    "                    generated = ''\n",
    "                else:\n",
    "                    generated = [] #simple initialization\n",
    "                #selects a random sentence from my input dataset.\n",
    "                sentence = text[start_index: start_index + maxlen]\n",
    "                seed_sentence = text[start_index: start_index + maxlen]\n",
    "\n",
    "                if character_mode:\n",
    "                    generated += sentence\n",
    "                else:\n",
    "                    #at first iteration i just add my input sentence in my generated element\n",
    "                    generated = generated + sentence\n",
    "\n",
    "\n",
    "                print('----- Generating with seed:')\n",
    "\n",
    "                if character_mode:\n",
    "                    print(sentence)\n",
    "                    sys.stdout.write(generated)\n",
    "                else:\n",
    "                    print(' '.join(sentence))\n",
    "\n",
    "                for i in range(num_char_pred): \n",
    "                    # if generated.endswith('_END_'):\n",
    "                    # \tbreak\n",
    "                    x = np.zeros((1, maxlen, num_chars)) #initialization of input. Matrix of maxlen words, each \n",
    "\n",
    "                    for t, char in enumerate(sentence):\n",
    "                        x[0, t, char_indices[char]] = 1. \n",
    "\n",
    "                    preds = model.predict(x, verbose=0)[0] \n",
    "                    #print('printo la prediction')\n",
    "                    #print(preds)\n",
    "                    next_index = sample(preds, diversity)\n",
    "                    next_char = indices_char[next_index]\n",
    "                    #print('printo il next char')\n",
    "                    #print(next_char)\n",
    "\n",
    "                    if character_mode:\n",
    "                        generated += next_char\n",
    "                        sentence = sentence[1:] + next_char\n",
    "                    else:\n",
    "                        generated.append(next_char)\n",
    "                        sentence = sentence[1:]\n",
    "                        sentence.append(next_char)\n",
    "                        #print('printo la sentence generata')\n",
    "                        #print(generated)\n",
    "\n",
    "                    if character_mode:\n",
    "                        sys.stdout.write(next_char)\n",
    "                    # else:\n",
    "                    # \tfor ch in next_char:\n",
    "                    # \t\tsys.stdout.write(ch)\t\n",
    "\n",
    "                    sys.stdout.flush()\n",
    "\n",
    "                if character_mode:\n",
    "                    f_write.write(seed_sentence + '\\n')\n",
    "                    f_write.write(generated)\n",
    "                else:\n",
    "                    f_write.write(' '.join(seed_sentence))\n",
    "                    \n",
    "                    f_write.write(' ' .join(generated))\n",
    "\n",
    "        np.save('%sloss_%s.npy'%(result_directory, prefix), loss_history)\n",
    "\n",
    "    print ('Done! You might want to run main_post_process.py to get midi files. ')\n",
    "    print ('You need python-midi (https://github.com/vishnubob/python-midi) to run it.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 1645119\n",
      "total chars: 8\n",
      "nb sequences: 8729\n",
      "Vectorization...\n",
      "Entering initialization cycle\n",
      "Completed Vectorization\n",
      "Build model...\n",
      "--------------------------------------------------\n",
      "Iteration 1\n",
      "Saving model after 1 epochs...\n",
      "[array([[ 1.7133920e-01,  2.3718972e-02,  2.8375231e-02, ...,\n",
      "         1.8733449e-02, -1.2332803e-01,  2.5276637e-02],\n",
      "       [-7.4440278e-02,  3.5527822e-02, -3.5186484e-02, ...,\n",
      "        -6.1535466e-02, -9.2516050e-02, -5.3737961e-02],\n",
      "       [-6.4444153e-05,  3.2625616e-02, -3.4133773e-02, ...,\n",
      "        -1.4260120e-02, -8.1129618e-02, -6.0778745e-02],\n",
      "       ...,\n",
      "       [ 9.9104054e-02,  1.3809559e-01,  7.0581334e-03, ...,\n",
      "         1.2299296e-02,  2.8581014e-02, -4.2892694e-02],\n",
      "       [ 9.0375721e-02, -3.0946923e-02, -6.3343220e-03, ...,\n",
      "        -5.3531710e-02,  2.9739350e-02, -1.2777895e-01],\n",
      "       [-8.5773475e-02,  1.6487125e-02,  7.8411728e-02, ...,\n",
      "        -2.8007526e-02, -3.2484621e-02,  6.2773172e-03]], dtype=float32), array([[-0.01546332,  0.03503912,  0.01723128, ...,  0.01863139,\n",
      "        -0.01100646, -0.04152421],\n",
      "       [ 0.03503605,  0.03097671, -0.0312785 , ...,  0.02283739,\n",
      "         0.02330812, -0.01417776],\n",
      "       [-0.0087197 , -0.0032378 ,  0.01530233, ...,  0.00051651,\n",
      "        -0.09597603,  0.01290515],\n",
      "       ...,\n",
      "       [ 0.00238318, -0.03074186, -0.04090142, ...,  0.01060304,\n",
      "         0.02266131,  0.01451782],\n",
      "       [ 0.01742959, -0.07834287, -0.01351483, ...,  0.04297324,\n",
      "         0.09565451,  0.04666052],\n",
      "       [-0.01828787,  0.00743229,  0.03976051, ...,  0.00647912,\n",
      "        -0.07503157, -0.03881307]], dtype=float32), array([-0.04734764,  0.00253541,  0.0121421 , ..., -0.03879068,\n",
      "       -0.09090939, -0.05260551], dtype=float32), array([[ 0.05554902,  0.06486528,  0.04130212, ..., -0.04886334,\n",
      "         0.07868866, -0.0202042 ],\n",
      "       [-0.03315216,  0.02358463, -0.00217718, ..., -0.01769658,\n",
      "         0.00532615,  0.00750567],\n",
      "       [ 0.02335501,  0.0396084 , -0.02992753, ..., -0.0293091 ,\n",
      "        -0.01200817,  0.0164506 ],\n",
      "       ...,\n",
      "       [-0.04548362,  0.02449102, -0.00656701, ...,  0.06399492,\n",
      "         0.01951218,  0.0029417 ],\n",
      "       [-0.04362691,  0.05759388,  0.04468933, ..., -0.04418949,\n",
      "        -0.05000085,  0.0351605 ],\n",
      "       [-0.02838363, -0.0030353 , -0.00259755, ...,  0.00228491,\n",
      "         0.01573087,  0.01584814]], dtype=float32), array([[ 0.0215831 , -0.00837604,  0.00293302, ...,  0.00619512,\n",
      "         0.01503693,  0.03573617],\n",
      "       [-0.01316745, -0.05210053,  0.01722137, ..., -0.00509231,\n",
      "         0.02383989,  0.02353008],\n",
      "       [-0.02017442, -0.00553085, -0.00285442, ..., -0.00273147,\n",
      "         0.00803364, -0.00265481],\n",
      "       ...,\n",
      "       [-0.0401147 ,  0.0043138 ,  0.04549769, ...,  0.04566871,\n",
      "         0.05706908,  0.08524796],\n",
      "       [ 0.02062813,  0.00232685, -0.06568442, ..., -0.05937662,\n",
      "        -0.02784089, -0.0271499 ],\n",
      "       [ 0.04725055, -0.00130676, -0.00162703, ...,  0.01979963,\n",
      "        -0.01308266,  0.01267479]], dtype=float32), array([ 0.02060402, -0.00125529, -0.00990582, ...,  0.04118675,\n",
      "       -0.0191244 ,  0.04654928], dtype=float32), array([[-0.04329892, -0.08253875,  0.10956441, ...,  0.05118402,\n",
      "        -0.06741937,  0.03568317],\n",
      "       [-0.03881192, -0.01196029,  0.07099921, ...,  0.02555331,\n",
      "        -0.02013019,  0.00611301],\n",
      "       [-0.08358434, -0.04232872, -0.03472342, ...,  0.04021528,\n",
      "         0.03218048,  0.00613128],\n",
      "       ...,\n",
      "       [-0.03157128,  0.10364315,  0.04557025, ...,  0.04302956,\n",
      "        -0.00151894,  0.05308793],\n",
      "       [ 0.06900474,  0.03169154,  0.00807178, ...,  0.03677822,\n",
      "         0.07849558,  0.01352535],\n",
      "       [-0.00310778, -0.09001026,  0.13585953, ...,  0.10684218,\n",
      "        -0.02340855,  0.10848318]], dtype=float32), array([-0.04653011,  0.06142079, -0.08284736, -0.06214074, -0.05957965,\n",
      "       -0.06391235,  0.01674318, -0.03015143], dtype=float32)]\n",
      "\n",
      "----- diversity: 0.9\n",
      "----- Generating with seed:\n",
      "0b000000000 0b000000000 0b000000000 0b011000000 0b001000000 0b001000000 0b001000000 0b001000000 0b001000000 0b000000000 0b000000000 0b001000000 0b001000000 0b001000000 0b001000000 0b001000000 0b001000000 0b000000000 0b000000000 BAR 0b101000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b111000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b010000000 0b000000000 0b000000000 0b000000000 BAR 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b101000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b111000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 BAR 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b111000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b001000000 0b000000000 0b011000000 0b000000000 0b001000000 0b000000000 BAR 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b101000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b011000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 BAR 0b101000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b011000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b010000000 0b000000000 0b000000000 0b000000000 BAR 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b100000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b100000000 0b000000000 0b000000000 0b000000000 0b000000000 0b111000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 BAR 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b111000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b000000000 0b001000000 0b000000000 0b001000000 0b000000000 0b011000000 0b000000000 0b001000000 0b000000000 BAR 0b001000000 0b000000000 0b000000000 0b000000000 0b000000000\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_distributed_function_2073]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-ec9775ede022>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-4a56ef057190>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(is_character, maxlen, num_units, model_prefix)\u001b[0m\n\u001b[0;32m    164\u001b[0m                         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_indices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m                     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m                     \u001b[1;31m#print('printo la prediction')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                     \u001b[1;31m#print(preds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 498\u001b[1;33m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[1;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m               total_epochs=1)\n\u001b[0m\u001b[0;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    636\u001b[0m               *args, **kwds)\n\u001b[0;32m    637\u001b[0m       \u001b[1;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TrapGenerator\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[sequential/lstm/StatefulPartitionedCall]] [Op:__inference_distributed_function_2073]\n\nFunction call stack:\ndistributed_function -> distributed_function -> distributed_function\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5cb1fbaf2c42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model_weights.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.load_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
